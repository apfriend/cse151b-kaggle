{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"../data/test-data\"\n",
    "val_path=\"../data/validation-data\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)\n",
    "train_dataset=ArgoverseDataset(data_path=train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_sz, \n",
    "    shuffle = False, \n",
    "    collate_fn=my_collate, \n",
    "    num_workers=0\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz, \n",
    "    shuffle = False, \n",
    "    collate_fn=my_collate, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0e74544fbc5e>:7: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inp = torch.LongTensor(inp)\n",
      "<ipython-input-6-0e74544fbc5e>:8: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  out = torch.LongTensor(out)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a random agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "#         axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "#         axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataLoader in module torch.utils.data.dataloader object:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(*args, **kwds)\n",
      " |  \n",
      " |  Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      " |  the given dataset.\n",
      " |  \n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |  \n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |  \n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |  \n",
      " |  \n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |  \n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |  \n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |  \n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |  \n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Union[int, NoneType] = 1, shuffle: bool = False, sampler: Union[torch.utils.data.sampler.Sampler[int], NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence[int]], NoneType] = None, num_workers: int = 0, collate_fn: Callable[[List[~T]], Any] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Callable[[int], NoneType] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  check_worker_number_rationality(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  multiprocessing_context\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_iterator': typing.Union[ForwardRef('_BaseDataLoad...\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51486"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['city', 'lane', 'lane_norm', 'scene_idx', 'agent_id', 'car_mask', 'p_in', 'v_in', 'p_out', 'v_out', 'track_id'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file='/home/apfriend/ucsd/CURRENT/cse151b/kaggle/data/new_train/new_train/0.pkl'\n",
    "with open(train_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'PIT',\n",
       " 'lane': array([[3278.8716, 1968.7596,    0.    ],\n",
       "        [3282.6606, 1972.2533,    0.    ],\n",
       "        [3286.4429, 1975.7545,    0.    ],\n",
       "        [3290.2249, 1979.2559,    0.    ],\n",
       "        [3294.007 , 1982.7572,    0.    ],\n",
       "        [3297.789 , 1986.2584,    0.    ],\n",
       "        [3301.5713, 1989.7598,    0.    ],\n",
       "        [3305.3533, 1993.2611,    0.    ],\n",
       "        [3309.1355, 1996.7623,    0.    ],\n",
       "        [3269.4802, 1967.0625,    0.    ],\n",
       "        [3267.2764, 1965.0217,    0.    ],\n",
       "        [3265.0664, 1962.9877,    0.    ],\n",
       "        [3262.8562, 1960.9536,    0.    ],\n",
       "        [3260.646 , 1958.9197,    0.    ],\n",
       "        [3258.436 , 1956.8856,    0.    ],\n",
       "        [3256.2258, 1954.8517,    0.    ],\n",
       "        [3254.0132, 1952.8207,    0.    ],\n",
       "        [3251.7898, 1950.8013,    0.    ],\n",
       "        [3235.7622, 1935.9915,    0.    ],\n",
       "        [3231.5237, 1932.1249,    0.    ],\n",
       "        [3227.2852, 1928.2582,    0.    ],\n",
       "        [3223.0923, 1924.343 ,    0.    ],\n",
       "        [3218.9045, 1920.4214,    0.    ],\n",
       "        [3214.7097, 1916.5073,    0.    ],\n",
       "        [3210.515 , 1912.5933,    0.    ],\n",
       "        [3206.3198, 1908.6793,    0.    ],\n",
       "        [3202.125 , 1904.7653,    0.    ],\n",
       "        [3257.3713, 1948.8804,    0.    ],\n",
       "        [3259.5886, 1950.9248,    0.    ],\n",
       "        [3261.8032, 1952.972 ,    0.    ],\n",
       "        [3264.018 , 1955.0194,    0.    ],\n",
       "        [3266.2327, 1957.0667,    0.    ],\n",
       "        [3268.4475, 1959.114 ,    0.    ],\n",
       "        [3270.6619, 1961.1615,    0.    ],\n",
       "        [3272.8704, 1963.2156,    0.    ],\n",
       "        [3275.0789, 1965.2697,    0.    ],\n",
       "        [3250.4824, 1949.5826,    0.    ],\n",
       "        [3249.175 , 1948.364 ,    0.    ],\n",
       "        [3247.8677, 1947.1453,    0.    ],\n",
       "        [3246.5603, 1945.9266,    0.    ],\n",
       "        [3245.253 , 1944.7081,    0.    ],\n",
       "        [3243.9443, 1943.4907,    0.    ],\n",
       "        [3242.6338, 1942.2755,    0.    ],\n",
       "        [3241.317 , 1941.0673,    0.    ],\n",
       "        [3240.    , 1939.859 ,    0.    ],\n",
       "        [3241.6833, 1934.2916,    0.    ],\n",
       "        [3243.3665, 1935.8604,    0.    ],\n",
       "        [3245.0498, 1937.4291,    0.    ],\n",
       "        [3246.7332, 1938.9977,    0.    ],\n",
       "        [3248.4153, 1940.5676,    0.    ],\n",
       "        [3250.0972, 1942.1377,    0.    ],\n",
       "        [3251.7793, 1943.7078,    0.    ],\n",
       "        [3253.4612, 1945.2777,    0.    ],\n",
       "        [3255.1433, 1946.8478,    0.    ],\n",
       "        [3209.2793, 1904.4741,    0.    ],\n",
       "        [3213.136 , 1907.9872,    0.    ],\n",
       "        [3216.9924, 1911.5002,    0.    ],\n",
       "        [3220.849 , 1915.0134,    0.    ],\n",
       "        [3224.7056, 1918.5265,    0.    ],\n",
       "        [3228.5376, 1922.0667,    0.    ],\n",
       "        [3232.3584, 1925.6188,    0.    ],\n",
       "        [3236.1792, 1929.1709,    0.    ],\n",
       "        [3240.    , 1932.723 ,    0.    ],\n",
       "        [3301.7441, 1996.9043,    0.    ],\n",
       "        [3297.9888, 1993.4269,    0.    ],\n",
       "        [3294.2334, 1989.9493,    0.    ],\n",
       "        [3290.478 , 1986.4718,    0.    ],\n",
       "        [3286.723 , 1982.9943,    0.    ],\n",
       "        [3282.9675, 1979.5168,    0.    ],\n",
       "        [3279.2122, 1976.0393,    0.    ],\n",
       "        [3275.45  , 1972.5695,    0.    ],\n",
       "        [3271.684 , 1969.1033,    0.    ]], dtype=float32),\n",
       " 'lane_norm': array([[ 3.7926118,  3.4899662,  0.       ],\n",
       "        [ 3.7891939,  3.493656 ,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [ 3.7821107,  3.5013022,  0.       ],\n",
       "        [-2.2038643, -2.0407646,  0.       ],\n",
       "        [-2.2038643, -2.0407646,  0.       ],\n",
       "        [-2.2099981, -2.034115 ,  0.       ],\n",
       "        [-2.2101107, -2.0339932,  0.       ],\n",
       "        [-2.2101107, -2.0339932,  0.       ],\n",
       "        [-2.2101107, -2.0339932,  0.       ],\n",
       "        [-2.2101107, -2.0339932,  0.       ],\n",
       "        [-2.2128086, -2.031011 ,  0.       ],\n",
       "        [-2.2233925, -2.0193133,  0.       ],\n",
       "        [-4.2377634, -3.867525 ,  0.       ],\n",
       "        [-4.2385526, -3.8666508,  0.       ],\n",
       "        [-4.2385526, -3.8666508,  0.       ],\n",
       "        [-4.1928964, -3.915217 ,  0.       ],\n",
       "        [-4.18762  , -3.9216042,  0.       ],\n",
       "        [-4.194902 , -3.9140232,  0.       ],\n",
       "        [-4.194902 , -3.9140232,  0.       ],\n",
       "        [-4.194902 , -3.9140232,  0.       ],\n",
       "        [-4.194902 , -3.9140232,  0.       ],\n",
       "        [ 2.2279737,  2.0326355,  0.       ],\n",
       "        [ 2.21739  ,  2.044333 ,  0.       ],\n",
       "        [ 2.2146919,  2.0473151,  0.       ],\n",
       "        [ 2.2146919,  2.0473151,  0.       ],\n",
       "        [ 2.2146919,  2.0473151,  0.       ],\n",
       "        [ 2.2146919,  2.0473151,  0.       ],\n",
       "        [ 2.2145793,  2.047437 ,  0.       ],\n",
       "        [ 2.2084455,  2.0540864,  0.       ],\n",
       "        [ 2.2084455,  2.0540864,  0.       ],\n",
       "        [-1.3073287, -1.2186704,  0.       ],\n",
       "        [-1.3073287, -1.2186704,  0.       ],\n",
       "        [-1.3073287, -1.2186704,  0.       ],\n",
       "        [-1.3073287, -1.2186704,  0.       ],\n",
       "        [-1.3074168, -1.2185754,  0.       ],\n",
       "        [-1.3085924, -1.217308 ,  0.       ],\n",
       "        [-1.3105348, -1.2151992,  0.       ],\n",
       "        [-1.3169104, -1.2082771,  0.       ],\n",
       "        [-1.3169104, -1.2082771,  0.       ],\n",
       "        [ 1.6832775,  1.5686753,  0.       ],\n",
       "        [ 1.6832775,  1.5686753,  0.       ],\n",
       "        [ 1.6832775,  1.5686753,  0.       ],\n",
       "        [ 1.6832775,  1.5686753,  0.       ],\n",
       "        [ 1.6821018,  1.5699425,  0.       ],\n",
       "        [ 1.6820138,  1.5700375,  0.       ],\n",
       "        [ 1.6820138,  1.5700375,  0.       ],\n",
       "        [ 1.6820138,  1.5700375,  0.       ],\n",
       "        [ 1.6820138,  1.5700375,  0.       ],\n",
       "        [ 3.8565755,  3.5131114,  0.       ],\n",
       "        [ 3.8565755,  3.5131114,  0.       ],\n",
       "        [ 3.8565755,  3.5131114,  0.       ],\n",
       "        [ 3.8565755,  3.5131114,  0.       ],\n",
       "        [ 3.8565755,  3.5131114,  0.       ],\n",
       "        [ 3.8317971,  3.5401535,  0.       ],\n",
       "        [ 3.82084  ,  3.5521119,  0.       ],\n",
       "        [ 3.82084  ,  3.5521119,  0.       ],\n",
       "        [ 3.82084  ,  3.5521119,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7553015, -3.4775062,  0.       ],\n",
       "        [-3.7623844, -3.4698598,  0.       ],\n",
       "        [-3.7658024, -3.46617  ,  0.       ]], dtype=float32),\n",
       " 'scene_idx': 0,\n",
       " 'agent_id': '00000000-0000-0000-0000-000000000062',\n",
       " 'car_mask': array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32),\n",
       " 'p_in': array([[[3277.29638672, 1947.62609863],\n",
       "         [3277.29614258, 1947.62597656],\n",
       "         [3277.29614258, 1947.62585449],\n",
       "         ...,\n",
       "         [3277.29638672, 1947.62561035],\n",
       "         [3277.29638672, 1947.62573242],\n",
       "         [3277.29638672, 1947.62585449]],\n",
       " \n",
       "        [[3277.13671875, 1977.72497559],\n",
       "         [3277.09350586, 1977.68725586],\n",
       "         [3277.22485352, 1977.82250977],\n",
       "         ...,\n",
       "         [3277.07397461, 1977.65368652],\n",
       "         [3277.16162109, 1977.72570801],\n",
       "         [3277.17016602, 1977.72717285]],\n",
       " \n",
       "        [[3232.28955078, 1922.98181152],\n",
       "         [3232.33007812, 1922.80908203],\n",
       "         [3232.28295898, 1923.0201416 ],\n",
       "         ...,\n",
       "         [3232.28857422, 1922.87341309],\n",
       "         [3232.35107422, 1922.92980957],\n",
       "         [3232.2590332 , 1922.96984863]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         ...,\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ]],\n",
       " \n",
       "        [[   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         ...,\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ]],\n",
       " \n",
       "        [[   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         ...,\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ]]]),\n",
       " 'v_in': array([[[-2.74871185e-04, -2.38232431e-04],\n",
       "         [-1.68325368e-03, -3.60875274e-04],\n",
       "         [ 1.27185765e-03, -1.43322884e-03],\n",
       "         ...,\n",
       "         [-4.68495244e-04, -1.28384610e-03],\n",
       "         [ 6.83214806e-04,  1.19478977e-03],\n",
       "         [ 4.27729276e-04,  4.41675016e-04]],\n",
       " \n",
       "        [[ 4.56323892e-01,  2.66867459e-01],\n",
       "         [-4.31315631e-01, -3.78357410e-01],\n",
       "         [ 1.31282473e+00,  1.35330689e+00],\n",
       "         ...,\n",
       "         [-6.44693255e-01, -1.17246592e+00],\n",
       "         [ 8.76227975e-01,  7.19912112e-01],\n",
       "         [ 8.46902654e-02,  1.45877255e-02]],\n",
       " \n",
       "        [[-2.41089724e-02,  1.41239002e-01],\n",
       "         [ 4.04870093e-01, -1.72706997e+00],\n",
       "         [-4.71843183e-01,  2.11047459e+00],\n",
       "         ...,\n",
       "         [-6.15702309e-02,  4.12303656e-01],\n",
       "         [ 6.26155555e-01,  5.63211381e-01],\n",
       "         [-9.20940161e-01,  4.00726646e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]]]),\n",
       " 'p_out': array([[[3277.29638672, 1947.62573242],\n",
       "         [3277.29614258, 1947.62548828],\n",
       "         [3277.29589844, 1947.62536621],\n",
       "         ...,\n",
       "         [3277.29541016, 1947.62646484],\n",
       "         [3277.29541016, 1947.62646484],\n",
       "         [3277.29541016, 1947.62670898]],\n",
       " \n",
       "        [[3277.15771484, 1977.7611084 ],\n",
       "         [3277.16625977, 1977.69189453],\n",
       "         [3277.14941406, 1977.75964355],\n",
       "         ...,\n",
       "         [3277.1340332 , 1977.74291992],\n",
       "         [3277.1496582 , 1977.73718262],\n",
       "         [3277.1496582 , 1977.73718262]],\n",
       " \n",
       "        [[3232.32006836, 1922.80334473],\n",
       "         [3232.31762695, 1922.79418945],\n",
       "         [3232.29296875, 1922.82763672],\n",
       "         ...,\n",
       "         [3232.28808594, 1922.85314941],\n",
       "         [3232.29101562, 1922.82666016],\n",
       "         [3232.29101562, 1922.82666016]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         ...,\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ]],\n",
       " \n",
       "        [[   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         ...,\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ]],\n",
       " \n",
       "        [[   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         ...,\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ],\n",
       "         [   0.        ,    0.        ]]]),\n",
       " 'v_out': array([[[ 2.23074952e-04, -7.17567338e-04],\n",
       "         [-2.14161561e-03, -2.68083508e-03],\n",
       "         [-2.10844958e-03, -1.38447585e-03],\n",
       "         ...,\n",
       "         [-3.12039308e-04,  3.49857635e-03],\n",
       "         [-1.13467422e-05,  8.84994690e-04],\n",
       "         [-7.37932278e-04,  2.20256718e-03]],\n",
       " \n",
       "        [[-1.23664290e-01,  3.38962704e-01],\n",
       "         [ 8.55064988e-02, -6.91424370e-01],\n",
       "         [-1.69878080e-01,  6.77078724e-01],\n",
       "         ...,\n",
       "         [-6.44134939e-01,  2.26514712e-02],\n",
       "         [ 1.56958163e-01, -5.63322864e-02],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 6.11260235e-01, -1.66518033e+00],\n",
       "         [-2.43129265e-02, -9.12000611e-02],\n",
       "         [-2.46453330e-01,  3.33999157e-01],\n",
       "         ...,\n",
       "         [-3.75109762e-01,  3.75737846e-01],\n",
       "         [ 2.91352477e-02, -2.65047491e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00]]]),\n",
       " 'track_id': array([[['00000000-0000-0000-0000-000000000000'],\n",
       "         ['00000000-0000-0000-0000-000000000000'],\n",
       "         ['00000000-0000-0000-0000-000000000000'],\n",
       "         ...,\n",
       "         ['00000000-0000-0000-0000-000000000000'],\n",
       "         ['00000000-0000-0000-0000-000000000000'],\n",
       "         ['00000000-0000-0000-0000-000000000000']],\n",
       " \n",
       "        [['00000000-0000-0000-0000-000000000007'],\n",
       "         ['00000000-0000-0000-0000-000000000007'],\n",
       "         ['00000000-0000-0000-0000-000000000007'],\n",
       "         ...,\n",
       "         ['00000000-0000-0000-0000-000000000007'],\n",
       "         ['00000000-0000-0000-0000-000000000007'],\n",
       "         ['00000000-0000-0000-0000-000000000007']],\n",
       " \n",
       "        [['00000000-0000-0000-0000-000000000009'],\n",
       "         ['00000000-0000-0000-0000-000000000009'],\n",
       "         ['00000000-0000-0000-0000-000000000009'],\n",
       "         ...,\n",
       "         ['00000000-0000-0000-0000-000000000009'],\n",
       "         ['00000000-0000-0000-0000-000000000009'],\n",
       "         ['00000000-0000-0000-0000-000000000009']],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [['dummy51'],\n",
       "         ['dummy51'],\n",
       "         ['dummy51'],\n",
       "         ...,\n",
       "         ['dummy51'],\n",
       "         ['dummy51'],\n",
       "         ['dummy51']],\n",
       " \n",
       "        [['dummy52'],\n",
       "         ['dummy52'],\n",
       "         ['dummy52'],\n",
       "         ...,\n",
       "         ['dummy52'],\n",
       "         ['dummy52'],\n",
       "         ['dummy52']],\n",
       " \n",
       "        [['dummy53'],\n",
       "         ['dummy53'],\n",
       "         ['dummy53'],\n",
       "         ...,\n",
       "         ['dummy53'],\n",
       "         ['dummy53'],\n",
       "         ['dummy53']]], dtype=object)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 72, 60, 60, 60, 60]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors=['lane', 'lane_norm','car_mask', 'p_in', 'v_in','track_id']\n",
    "[len(data[p]) for p in predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-0e74544fbc5e>:7: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inp = torch.LongTensor(inp)\n",
      "<ipython-input-3-0e74544fbc5e>:8: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  out = torch.LongTensor(out)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b2ea303ad87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for idx, batch, in enumerate(train_loader):\n",
    "    print(batch[\"predictors\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
