{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./data/new_train/new_train/\"\n",
    "val_path=\"./data/new_val_in/new_val_in\"\n",
    "\n",
    "device='cuda'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=train_path)\n",
    "val_dataset=ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz =256\n",
    "n_workers=4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "#     inp = torch.LongTensor(inp)\n",
    "#     out = torch.LongTensor(out)\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=True,\n",
    "    collate_fn=my_collate,\n",
    "    num_workers=n_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_sz, \n",
    "    shuffle = False, \n",
    "    collate_fn=my_collate, \n",
    "    num_workers=n_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        \n",
    "        # the LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim\n",
    "        self.hidden_dim=2048\n",
    "        self.num_layers=3\n",
    "        self.device=device\n",
    "        self.lstm=nn.LSTM(\n",
    "            input_size=240,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True            \n",
    "        )\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.linear=nn.Conv1d(\n",
    "            in_channels=self.hidden_dim,\n",
    "            out_channels=240,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #batch_size x timesteps x 240\n",
    "        x,_=self.lstm(x)\n",
    "        # finally hidden layer batch_size x timesteps x hidden_dim\n",
    "        x=x.transpose(1,2)\n",
    "        # batch_size x hidden_dim x timesteps\n",
    "        x=self.linear(x)\n",
    "        x=x.transpose(1,2)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def forward_test(self, x, num_steps=30):\n",
    "        res=[]\n",
    "        h=torch.zeros((self.num_layers, len(x), self.hidden_dim)).to(self.device)\n",
    "        c=torch.zeros((self.num_layers, len(x), self.hidden_dim)).to(self.device)\n",
    "        for step in range(num_steps):\n",
    "            x, (h,c)=self.lstm(x, (h,c))\n",
    "            x=x[:,-1:]\n",
    "            x=x.transpose(1,2)\n",
    "            x=self.linear(x)\n",
    "            x=x.transpose(1,2)\n",
    "            res.append(x)\n",
    "        res=torch.cat(res,1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class tqdm in module tqdm.std:\n",
      "\n",
      "class tqdm(tqdm.utils.Comparable)\n",
      " |  tqdm(*_, **__)\n",
      " |  \n",
      " |  Decorate an iterable object, returning an iterator which acts exactly\n",
      " |  like the original iterable, but prints a dynamically updating\n",
      " |  progressbar every time a value is requested.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      tqdm\n",
      " |      tqdm.utils.Comparable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, iterable=None, desc=None, total=None, leave=True, file=None, ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None, ascii=None, disable=False, unit='it', unit_scale=False, dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0, position=None, postfix=None, unit_divisor=1000, write_bytes=None, lock_args=None, nrows=None, colour=None, delay=0, gui=False, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      iterable  : iterable, optional\n",
      " |          Iterable to decorate with a progressbar.\n",
      " |          Leave blank to manually manage the updates.\n",
      " |      desc  : str, optional\n",
      " |          Prefix for the progressbar.\n",
      " |      total  : int or float, optional\n",
      " |          The number of expected iterations. If unspecified,\n",
      " |          len(iterable) is used if possible. If float(\"inf\") or as a last\n",
      " |          resort, only basic progress statistics are displayed\n",
      " |          (no ETA, no progressbar).\n",
      " |          If `gui` is True and this parameter needs subsequent updating,\n",
      " |          specify an initial arbitrary large positive number,\n",
      " |          e.g. 9e9.\n",
      " |      leave  : bool, optional\n",
      " |          If [default: True], keeps all traces of the progressbar\n",
      " |          upon termination of iteration.\n",
      " |          If `None`, will leave only if `position` is `0`.\n",
      " |      file  : `io.TextIOWrapper` or `io.StringIO`, optional\n",
      " |          Specifies where to output the progress messages\n",
      " |          (default: sys.stderr). Uses `file.write(str)` and `file.flush()`\n",
      " |          methods.  For encoding, see `write_bytes`.\n",
      " |      ncols  : int, optional\n",
      " |          The width of the entire output message. If specified,\n",
      " |          dynamically resizes the progressbar to stay within this bound.\n",
      " |          If unspecified, attempts to use environment width. The\n",
      " |          fallback is a meter width of 10 and no limit for the counter and\n",
      " |          statistics. If 0, will not print any meter (only stats).\n",
      " |      mininterval  : float, optional\n",
      " |          Minimum progress display update interval [default: 0.1] seconds.\n",
      " |      maxinterval  : float, optional\n",
      " |          Maximum progress display update interval [default: 10] seconds.\n",
      " |          Automatically adjusts `miniters` to correspond to `mininterval`\n",
      " |          after long display update lag. Only works if `dynamic_miniters`\n",
      " |          or monitor thread is enabled.\n",
      " |      miniters  : int or float, optional\n",
      " |          Minimum progress display update interval, in iterations.\n",
      " |          If 0 and `dynamic_miniters`, will automatically adjust to equal\n",
      " |          `mininterval` (more CPU efficient, good for tight loops).\n",
      " |          If > 0, will skip display of specified number of iterations.\n",
      " |          Tweak this and `mininterval` to get very efficient loops.\n",
      " |          If your progress is erratic with both fast and slow iterations\n",
      " |          (network, skipping items, etc) you should set miniters=1.\n",
      " |      ascii  : bool or str, optional\n",
      " |          If unspecified or False, use unicode (smooth blocks) to fill\n",
      " |          the meter. The fallback is to use ASCII characters \" 123456789#\".\n",
      " |      disable  : bool, optional\n",
      " |          Whether to disable the entire progressbar wrapper\n",
      " |          [default: False]. If set to None, disable on non-TTY.\n",
      " |      unit  : str, optional\n",
      " |          String that will be used to define the unit of each iteration\n",
      " |          [default: it].\n",
      " |      unit_scale  : bool or int or float, optional\n",
      " |          If 1 or True, the number of iterations will be reduced/scaled\n",
      " |          automatically and a metric prefix following the\n",
      " |          International System of Units standard will be added\n",
      " |          (kilo, mega, etc.) [default: False]. If any other non-zero\n",
      " |          number, will scale `total` and `n`.\n",
      " |      dynamic_ncols  : bool, optional\n",
      " |          If set, constantly alters `ncols` and `nrows` to the\n",
      " |          environment (allowing for window resizes) [default: False].\n",
      " |      smoothing  : float, optional\n",
      " |          Exponential moving average smoothing factor for speed estimates\n",
      " |          (ignored in GUI mode). Ranges from 0 (average speed) to 1\n",
      " |          (current/instantaneous speed) [default: 0.3].\n",
      " |      bar_format  : str, optional\n",
      " |          Specify a custom bar string formatting. May impact performance.\n",
      " |          [default: '{l_bar}{bar}{r_bar}'], where\n",
      " |          l_bar='{desc}: {percentage:3.0f}%|' and\n",
      " |          r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n",
      " |            '{rate_fmt}{postfix}]'\n",
      " |          Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n",
      " |            percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n",
      " |            rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n",
      " |            rate_inv, rate_inv_fmt, postfix, unit_divisor,\n",
      " |            remaining, remaining_s, eta.\n",
      " |          Note that a trailing \": \" is automatically removed after {desc}\n",
      " |          if the latter is empty.\n",
      " |      initial  : int or float, optional\n",
      " |          The initial counter value. Useful when restarting a progress\n",
      " |          bar [default: 0]. If using float, consider specifying `{n:.3f}`\n",
      " |          or similar in `bar_format`, or specifying `unit_scale`.\n",
      " |      position  : int, optional\n",
      " |          Specify the line offset to print this bar (starting from 0)\n",
      " |          Automatic if unspecified.\n",
      " |          Useful to manage multiple bars at once (eg, from threads).\n",
      " |      postfix  : dict or *, optional\n",
      " |          Specify additional stats to display at the end of the bar.\n",
      " |          Calls `set_postfix(**postfix)` if possible (dict).\n",
      " |      unit_divisor  : float, optional\n",
      " |          [default: 1000], ignored unless `unit_scale` is True.\n",
      " |      write_bytes  : bool, optional\n",
      " |          If (default: None) and `file` is unspecified,\n",
      " |          bytes will be written in Python 2. If `True` will also write\n",
      " |          bytes. In all other cases will default to unicode.\n",
      " |      lock_args  : tuple, optional\n",
      " |          Passed to `refresh` for intermediate output\n",
      " |          (initialisation, iterating, and updating).\n",
      " |      nrows  : int, optional\n",
      " |          The screen height. If specified, hides nested bars outside this\n",
      " |          bound. If unspecified, attempts to use environment height.\n",
      " |          The fallback is 20.\n",
      " |      colour  : str, optional\n",
      " |          Bar colour (e.g. 'green', '#00ff00').\n",
      " |      delay  : float, optional\n",
      " |          Don't display until [default: 0] seconds have elapsed.\n",
      " |      gui  : bool, optional\n",
      " |          WARNING: internal parameter - do not use.\n",
      " |          Use tqdm.gui.tqdm(...) instead. If set, will attempt to use\n",
      " |          matplotlib animations for a graphical output [default: False].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : decorated iterator.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Backward-compatibility to use: for x in tqdm(iterable)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  clear(self, nolock=False)\n",
      " |      Clear current bar display.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Cleanup and (if leave=False) close the progressbar.\n",
      " |  \n",
      " |  display(self, msg=None, pos=None)\n",
      " |      Use `self.sp` to display `msg` in the specified `pos`.\n",
      " |      \n",
      " |      Consider overloading this function when inheriting to use e.g.:\n",
      " |      `self.some_frontend(**self.format_dict)` instead of `self.sp`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      msg  : str, optional. What to display (default: `repr(self)`).\n",
      " |      pos  : int, optional. Position to `moveto`\n",
      " |        (default: `abs(self.pos)`).\n",
      " |  \n",
      " |  moveto(self, n)\n",
      " |  \n",
      " |  refresh(self, nolock=False, lock_args=None)\n",
      " |      Force refresh the display of this bar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nolock  : bool, optional\n",
      " |          If `True`, does not lock.\n",
      " |          If [default: `False`]: calls `acquire()` on internal lock.\n",
      " |      lock_args  : tuple, optional\n",
      " |          Passed to internal lock's `acquire()`.\n",
      " |          If specified, will only `display()` if `acquire()` returns `True`.\n",
      " |  \n",
      " |  reset(self, total=None)\n",
      " |      Resets to 0 iterations for repeated use.\n",
      " |      \n",
      " |      Consider combining with `leave=True`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      total  : int or float, optional. Total to use for the new bar.\n",
      " |  \n",
      " |  set_description(self, desc=None, refresh=True)\n",
      " |      Set/modify description of the progress bar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      desc  : str, optional\n",
      " |      refresh  : bool, optional\n",
      " |          Forces refresh [default: True].\n",
      " |  \n",
      " |  set_description_str(self, desc=None, refresh=True)\n",
      " |      Set/modify description without ': ' appended.\n",
      " |  \n",
      " |  set_postfix(self, ordered_dict=None, refresh=True, **kwargs)\n",
      " |      Set/modify postfix (additional stats)\n",
      " |      with automatic formatting based on datatype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ordered_dict  : dict or OrderedDict, optional\n",
      " |      refresh  : bool, optional\n",
      " |          Forces refresh [default: True].\n",
      " |      kwargs  : dict, optional\n",
      " |  \n",
      " |  set_postfix_str(self, s='', refresh=True)\n",
      " |      Postfix without dictionary expansion, similar to prefix handling.\n",
      " |  \n",
      " |  unpause(self)\n",
      " |      Restart tqdm timer from last print time.\n",
      " |  \n",
      " |  update(self, n=1)\n",
      " |      Manually update the progress bar, useful for streams\n",
      " |      such as reading files.\n",
      " |      E.g.:\n",
      " |      >>> t = tqdm(total=filesize) # Initialise\n",
      " |      >>> for current_buffer in stream:\n",
      " |      ...    ...\n",
      " |      ...    t.update(len(current_buffer))\n",
      " |      >>> t.close()\n",
      " |      The last line is highly recommended, but possibly not necessary if\n",
      " |      `t.update()` will be called in such a way that `filesize` will be\n",
      " |      exactly reached and printed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int or float, optional\n",
      " |          Increment to add to the internal counter of iterations\n",
      " |          [default: 1]. If using float, consider specifying `{n:.3f}`\n",
      " |          or similar in `bar_format`, or specifying `unit_scale`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : bool or None\n",
      " |          True if a `display()` was triggered.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  external_write_mode(file=None, nolock=False) from builtins.type\n",
      " |      Disable tqdm within context and refresh tqdm when exits.\n",
      " |      Useful when writing to standard output stream\n",
      " |  \n",
      " |  get_lock() from builtins.type\n",
      " |      Get the global lock. Construct it if it does not exist.\n",
      " |  \n",
      " |  pandas(**tqdm_kwargs) from builtins.type\n",
      " |      Registers the current `tqdm` class with\n",
      " |          pandas.core.\n",
      " |          ( frame.DataFrame\n",
      " |          | series.Series\n",
      " |          | groupby.(generic.)DataFrameGroupBy\n",
      " |          | groupby.(generic.)SeriesGroupBy\n",
      " |          ).progress_apply\n",
      " |      \n",
      " |      A new instance will be create every time `progress_apply` is called,\n",
      " |      and each instance will automatically `close()` upon completion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tqdm_kwargs  : arguments for the tqdm instance\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> from tqdm import tqdm\n",
      " |      >>> from tqdm.gui import tqdm as tqdm_gui\n",
      " |      >>>\n",
      " |      >>> df = pd.DataFrame(np.random.randint(0, 100, (100000, 6)))\n",
      " |      >>> tqdm.pandas(ncols=50)  # can use tqdm_gui, optional kwargs, etc\n",
      " |      >>> # Now you can use `progress_apply` instead of `apply`\n",
      " |      >>> df.groupby(0).progress_apply(lambda x: x**2)\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      <https://stackoverflow.com/questions/18603270/        progress-indicator-during-pandas-operations-python>\n",
      " |  \n",
      " |  set_lock(lock) from builtins.type\n",
      " |      Set the global lock.\n",
      " |  \n",
      " |  wrapattr(stream, method, total=None, bytes=True, **tqdm_kwargs) from builtins.type\n",
      " |      stream  : file-like object.\n",
      " |      method  : str, \"read\" or \"write\". The result of `read()` and\n",
      " |          the first argument of `write()` should have a `len()`.\n",
      " |      \n",
      " |      >>> with tqdm.wrapattr(file_obj, \"read\", total=file_obj.size) as fobj:\n",
      " |      ...     while True:\n",
      " |      ...         chunk = fobj.read(chunk_size)\n",
      " |      ...         if not chunk:\n",
      " |      ...             break\n",
      " |  \n",
      " |  write(s, file=None, end='\\n', nolock=False) from builtins.type\n",
      " |      Print a message via tqdm (without overlap with bars).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *_, **__)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  format_interval(t)\n",
      " |      Formats a number of seconds as a clock time, [H:]MM:SS\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      t  : int\n",
      " |          Number of seconds.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          [H:]MM:SS\n",
      " |  \n",
      " |  format_meter(n, total, elapsed, ncols=None, prefix='', ascii=False, unit='it', unit_scale=False, rate=None, bar_format=None, postfix=None, unit_divisor=1000, initial=0, colour=None, **extra_kwargs)\n",
      " |      Return a string-based progress bar given some parameters\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int or float\n",
      " |          Number of finished iterations.\n",
      " |      total  : int or float\n",
      " |          The expected total number of iterations. If meaningless (None),\n",
      " |          only basic progress statistics are displayed (no ETA).\n",
      " |      elapsed  : float\n",
      " |          Number of seconds passed since start.\n",
      " |      ncols  : int, optional\n",
      " |          The width of the entire output message. If specified,\n",
      " |          dynamically resizes `{bar}` to stay within this bound\n",
      " |          [default: None]. If `0`, will not print any bar (only stats).\n",
      " |          The fallback is `{bar:10}`.\n",
      " |      prefix  : str, optional\n",
      " |          Prefix message (included in total width) [default: ''].\n",
      " |          Use as {desc} in bar_format string.\n",
      " |      ascii  : bool, optional or str, optional\n",
      " |          If not set, use unicode (smooth blocks) to fill the meter\n",
      " |          [default: False]. The fallback is to use ASCII characters\n",
      " |          \" 123456789#\".\n",
      " |      unit  : str, optional\n",
      " |          The iteration unit [default: 'it'].\n",
      " |      unit_scale  : bool or int or float, optional\n",
      " |          If 1 or True, the number of iterations will be printed with an\n",
      " |          appropriate SI metric prefix (k = 10^3, M = 10^6, etc.)\n",
      " |          [default: False]. If any other non-zero number, will scale\n",
      " |          `total` and `n`.\n",
      " |      rate  : float, optional\n",
      " |          Manual override for iteration rate.\n",
      " |          If [default: None], uses n/elapsed.\n",
      " |      bar_format  : str, optional\n",
      " |          Specify a custom bar string formatting. May impact performance.\n",
      " |          [default: '{l_bar}{bar}{r_bar}'], where\n",
      " |          l_bar='{desc}: {percentage:3.0f}%|' and\n",
      " |          r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n",
      " |            '{rate_fmt}{postfix}]'\n",
      " |          Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n",
      " |            percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n",
      " |            rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n",
      " |            rate_inv, rate_inv_fmt, postfix, unit_divisor,\n",
      " |            remaining, remaining_s, eta.\n",
      " |          Note that a trailing \": \" is automatically removed after {desc}\n",
      " |          if the latter is empty.\n",
      " |      postfix  : *, optional\n",
      " |          Similar to `prefix`, but placed at the end\n",
      " |          (e.g. for additional stats).\n",
      " |          Note: postfix is usually a string (not a dict) for this method,\n",
      " |          and will if possible be set to postfix = ', ' + postfix.\n",
      " |          However other types are supported (#382).\n",
      " |      unit_divisor  : float, optional\n",
      " |          [default: 1000], ignored unless `unit_scale` is True.\n",
      " |      initial  : int or float, optional\n",
      " |          The initial counter value [default: 0].\n",
      " |      colour  : str, optional\n",
      " |          Bar colour (e.g. 'green', '#00ff00').\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : Formatted meter and stats, ready to display.\n",
      " |  \n",
      " |  format_num(n)\n",
      " |      Intelligent scientific notation (.3g).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int or float or Numeric\n",
      " |          A Number.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          Formatted number.\n",
      " |  \n",
      " |  format_sizeof(num, suffix='', divisor=1000)\n",
      " |      Formats a number (greater than unity) with SI Order of Magnitude\n",
      " |      prefixes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num  : float\n",
      " |          Number ( >= 1) to format.\n",
      " |      suffix  : str, optional\n",
      " |          Post-postfix [default: ''].\n",
      " |      divisor  : float, optional\n",
      " |          Divisor between prefixes [default: 1000].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          Number with Order of Magnitude SI unit postfix.\n",
      " |  \n",
      " |  status_printer(file)\n",
      " |      Manage the printing and in-place updating of a line of characters.\n",
      " |      Note that if the string is longer than a line, then in-place\n",
      " |      updating may not work (it will print a new line at each refresh).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  format_dict\n",
      " |      Public API for read-only member access.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  monitor = None\n",
      " |  \n",
      " |  monitor_interval = 10\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tqdm.utils.Comparable:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tqdm.utils.Comparable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "def train_lstm_model(lstm_model, data_loader, n_epochs, filename, ema_weight, device='cuda:0', verbose=False):\n",
    "    '''\n",
    "    Train LSTM model\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "        lstm_model - torch nerual network model\n",
    "            model to train\n",
    "        data_loader - torch DataLoader class \n",
    "            training data for model\n",
    "        n_epochs - int\n",
    "            number of epochs to train\n",
    "        filename - string\n",
    "            filepath to save training data to\n",
    "        ema_weight - float\n",
    "            float between (0.0,1.0) for the exponential moving average weight\n",
    "        device - string, default 'cuda'\n",
    "            choose to run on gpu ('cuda') or cpu ('CPU')\n",
    "        verbose - boolean, default False\n",
    "            If true print training progress every 10 training iterations\n",
    "    -------\n",
    "    Returns\n",
    "    -------\n",
    "         Trained LSTM model\n",
    "    '''\n",
    "    \n",
    "    model=lstm_model(device).to(device)\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    loss_ema=-1\n",
    "    loss_ema2=-1\n",
    "\n",
    "    data=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i_batch, sample_batch in enumerate(tqdm(train_loader, desc='Epoch %i/%i'%(epoch+1,n_epochs), disable=verbose)):\n",
    "            '''\n",
    "            TODO:\n",
    "            Deep learning model training routine\n",
    "            '''\n",
    "            inp, out=sample_batch\n",
    "            inp, out=inp.to(device), out.to(device)\n",
    "\n",
    "            # input: batch size x 60 x 49 x 4\n",
    "            # transpose: batch size x 49 x 240\n",
    "            mixed=torch.cat([inp, out], 2).transpose(1,2).reshape((-1,49,240))#.float()\n",
    "\n",
    "            y_pred=model(mixed[:,:-1])[:,-30:]\n",
    "            y_pred=y_pred.reshape((-1,30,60,4)).transpose(1,2)\n",
    "\n",
    "            loss=(torch.mean((y_pred-out)**2))**0.5\n",
    "            optimizer.zero_grad() # set gradient to zero\n",
    "            loss.backward() # backwards propogation\n",
    "            optimizer.step() #forward step\n",
    "\n",
    "            if loss_ema<0:\n",
    "                loss_ema=loss\n",
    "            loss_ema=loss_ema*ema_weight+loss*(1-ema_weight)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_pred2=model.forward_test(inp.transpose(1,2).reshape((-1,19,240)))\n",
    "                y_pred2=y_pred2.reshape((-1,30,60,4)).transpose(1,2)\n",
    "                loss2=torch.mean((y_pred2-out)**2)**0.5\n",
    "                if loss_ema2<0:\n",
    "                    loss_ema2=loss2\n",
    "                loss_ema2=loss_ema2*ema_weight+loss2*(1-ema_weight)\n",
    "\n",
    "            if verbose and i_batch%10==0:\n",
    "                loss_str='loss_full %i %i %f %f'%(epoch,i_batch,loss_ema.item(),loss.item())\n",
    "                loss2_str='loss_full %i %i %f %f'%(epoch,i_batch,loss_ema2.item(),loss2.item())\n",
    "                print(loss_str)\n",
    "                print(loss2_str)\n",
    "            \n",
    "            data.append([epoch, i_batch, loss_ema.item(), loss.item(), loss_ema2.item(), loss2.item()])\n",
    "    columns=[\"epoch\",\"iteration\",\"loss_ema\",\"loss\", \"loss_ema2\", \"loss2\"]\n",
    "    df=pd.DataFrame(dict(zip(columns, np.array(data).T)))\n",
    "    display(df)\n",
    "    df.to_csv(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 805/805 [31:37<00:00,  2.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>loss_ema</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_ema2</th>\n",
       "      <th>loss2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>578.336304</td>\n",
       "      <td>576.158752</td>\n",
       "      <td>578.187561</td>\n",
       "      <td>579.960693</td>\n",
       "      <td>582.095825</td>\n",
       "      <td>582.515503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578.336365</td>\n",
       "      <td>556.560852</td>\n",
       "      <td>596.447266</td>\n",
       "      <td>595.919128</td>\n",
       "      <td>601.312317</td>\n",
       "      <td>586.292847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578.275879</td>\n",
       "      <td>576.041382</td>\n",
       "      <td>578.035278</td>\n",
       "      <td>579.786621</td>\n",
       "      <td>581.900757</td>\n",
       "      <td>582.304321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>578.275879</td>\n",
       "      <td>555.930969</td>\n",
       "      <td>595.980530</td>\n",
       "      <td>595.549011</td>\n",
       "      <td>600.928162</td>\n",
       "      <td>585.935974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        epoch   iteration    loss_ema        loss   loss_ema2       loss2\n",
       "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "1    0.000000    1.000000    2.000000    3.000000    4.000000    5.000000\n",
       "2  578.336304  576.158752  578.187561  579.960693  582.095825  582.515503\n",
       "3  578.336365  556.560852  596.447266  595.919128  601.312317  586.292847\n",
       "4  578.275879  576.041382  578.035278  579.786621  581.900757  582.304321\n",
       "5  578.275879  555.930969  595.980530  595.549011  600.928162  585.935974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LSTM_model(\n",
       "  (lstm): LSTM(240, 2048, num_layers=3, batch_first=True)\n",
       "  (linear): Conv1d(2048, 240, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit -r1\n",
    "\n",
    "train_lstm_model(\n",
    "    lstm_model=LSTM_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=1,\n",
    "    filename='save-data/lsmt-test-090-2.csv',\n",
    "    ema_weight=0.9,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above model has iteration ~2.15+/-.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 0 607.931396 607.931396\n",
      "loss_full 0 0 607.870544 607.870544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:26<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 10 574.160217 561.601929\n",
      "loss_full 0 10 573.792419 561.216553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:48<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 20 569.431274 583.384094\n",
      "loss_full 0 20 569.035400 582.973999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [01:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 30 567.939087 569.132446\n",
      "loss_full 0 30 567.540771 568.732727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [01:32<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 40 565.619873 557.560486\n",
      "loss_full 0 40 565.229126 557.171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [01:54<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 50 573.362000 563.320007\n",
      "loss_full 0 50 572.977295 562.943054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [02:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 60 563.549316 558.083130\n",
      "loss_full 0 60 563.169800 557.710388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [02:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 70 563.033325 592.305298\n",
      "loss_full 0 70 562.669006 591.936768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [03:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 80 563.271484 553.431763\n",
      "loss_full 0 80 562.913452 553.080505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [03:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 90 560.703735 583.915833\n",
      "loss_full 0 90 560.348206 583.552307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [03:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 100 535.484070 517.107056\n",
      "loss_full 0 100 535.141602 516.767700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [04:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 110 551.103516 549.269104\n",
      "loss_full 0 110 550.768921 548.939331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [04:28<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 120 533.067017 530.916138\n",
      "loss_full 0 120 532.739685 530.596191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [04:50<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 130 539.607849 538.252991\n",
      "loss_full 0 130 539.283630 537.933594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [05:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 140 527.888000 525.553955\n",
      "loss_full 0 140 527.566345 525.236755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [05:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 150 528.028625 523.317139\n",
      "loss_full 0 150 527.715149 523.009216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [05:55<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 160 521.867493 516.456970\n",
      "loss_full 0 160 521.553833 516.138916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [06:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 170 531.292236 546.336487\n",
      "loss_full 0 170 530.980835 546.025208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [06:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 180 525.296875 543.682251\n",
      "loss_full 0 180 525.001953 543.387634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [07:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 190 520.205200 544.012329\n",
      "loss_full 0 190 519.908875 543.712830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [07:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 200 522.434021 546.168213\n",
      "loss_full 0 200 522.141541 545.875916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [07:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 210 516.203064 516.759888\n",
      "loss_full 0 210 515.922119 516.477173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [08:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 220 518.889709 539.860046\n",
      "loss_full 0 220 518.606567 539.575989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [08:26<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 230 502.287598 504.323456\n",
      "loss_full 0 230 502.011230 504.047089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [08:48<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 240 514.332825 509.208527\n",
      "loss_full 0 240 514.061584 508.937347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [09:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 250 507.020264 519.607239\n",
      "loss_full 0 250 506.755310 519.346741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [09:31<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 260 503.141632 517.043579\n",
      "loss_full 0 260 502.880219 516.776855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [09:53<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 270 503.853729 528.327759\n",
      "loss_full 0 270 503.598328 528.070129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [10:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 280 494.464447 489.513580\n",
      "loss_full 0 280 494.216400 489.269196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [10:34<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 290 495.616730 512.884399\n",
      "loss_full 0 290 495.366577 512.633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [10:53<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 300 488.990265 488.250519\n",
      "loss_full 0 300 488.748901 488.009491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [11:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 310 484.692444 483.371704\n",
      "loss_full 0 310 484.455841 483.126831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [11:31<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 320 496.042053 485.578430\n",
      "loss_full 0 320 495.804993 485.345337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [11:49<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 330 473.240631 462.179565\n",
      "loss_full 0 330 473.015015 461.961151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [12:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 340 488.296722 492.584839\n",
      "loss_full 0 340 488.071991 492.362518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [12:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 350 475.138000 460.156311\n",
      "loss_full 0 350 474.915070 459.927277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [12:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 360 485.110596 496.988525\n",
      "loss_full 0 360 484.889404 496.770782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [13:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 370 475.602417 467.347748\n",
      "loss_full 0 370 475.390198 467.130554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [13:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 380 461.309357 453.711578\n",
      "loss_full 0 380 461.103271 453.503143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [13:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 390 466.579926 477.353882\n",
      "loss_full 0 390 466.376892 477.143494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [14:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 400 472.223267 482.213837\n",
      "loss_full 0 400 472.020386 482.003296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [14:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 410 467.669952 464.669220\n",
      "loss_full 0 410 467.471680 464.467468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [14:40<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 420 464.614105 468.908539\n",
      "loss_full 0 420 464.419006 468.721497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [14:59<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 430 467.024475 493.874207\n",
      "loss_full 0 430 466.874207 493.784241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [15:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 440 456.592468 446.530579\n",
      "loss_full 0 440 456.466370 446.423920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [15:36<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 450 457.704224 456.369598\n",
      "loss_full 0 450 457.938904 456.719208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [15:55<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 460 454.784943 427.529877\n",
      "loss_full 0 460 454.743469 427.235626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [16:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 470 454.932281 432.659302\n",
      "loss_full 0 470 454.738037 432.460205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [16:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 480 465.400635 438.312805\n",
      "loss_full 0 480 465.147614 438.042999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [16:52<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 490 457.854828 462.534760\n",
      "loss_full 0 490 457.655579 462.220551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [17:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 500 452.764862 429.624115\n",
      "loss_full 0 500 452.738586 429.412323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [17:30<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 510 454.895111 472.852661\n",
      "loss_full 0 510 454.740540 472.676758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [17:49<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 520 452.558990 458.042999\n",
      "loss_full 0 520 452.396545 457.882355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [18:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 530 454.941620 456.832245\n",
      "loss_full 0 530 454.782471 456.673584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [18:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 540 456.475616 464.318970\n",
      "loss_full 0 540 456.321655 464.169128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [18:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 550 450.230225 434.227051\n",
      "loss_full 0 550 450.079468 434.081757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [19:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 560 445.063995 438.294769\n",
      "loss_full 0 560 444.908020 438.113464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [19:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 570 458.785339 489.228912\n",
      "loss_full 0 570 458.637787 489.078583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [19:42<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 580 447.103027 453.759491\n",
      "loss_full 0 580 446.958191 453.616150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [20:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 590 439.128540 412.757843\n",
      "loss_full 0 590 438.991150 412.623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [20:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 600 436.603729 443.416382\n",
      "loss_full 0 600 436.472107 443.292786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [20:39<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 610 445.968903 459.273590\n",
      "loss_full 0 610 445.841095 459.149567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [20:58<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 620 445.431671 447.358551\n",
      "loss_full 0 620 445.308289 447.234558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [21:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 630 449.549927 455.037994\n",
      "loss_full 0 630 449.428162 454.918762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [21:36<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 640 437.832947 423.631653\n",
      "loss_full 0 640 437.721741 423.533875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [21:55<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 650 432.142578 430.046204\n",
      "loss_full 0 650 432.037048 429.940491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [22:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 660 436.128265 432.244049\n",
      "loss_full 0 660 436.024963 432.144104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [22:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 670 432.797668 441.228210\n",
      "loss_full 0 670 432.692505 441.121307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [22:52<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 680 431.905792 422.012695\n",
      "loss_full 0 680 431.804260 421.915924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [23:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 690 433.344025 463.986847\n",
      "loss_full 0 690 433.241638 463.886322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [23:29<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 700 427.303619 427.043091\n",
      "loss_full 0 700 427.205200 426.946228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [23:48<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 710 422.470215 435.883392\n",
      "loss_full 0 710 422.378876 435.792572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [24:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 720 424.379059 408.044708\n",
      "loss_full 0 720 424.286407 407.942261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [24:26<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 730 427.473511 435.941193\n",
      "loss_full 0 730 427.384857 435.850494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [24:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 740 428.428284 420.834595\n",
      "loss_full 0 740 428.343201 420.751251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [25:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 750 421.276062 420.922577\n",
      "loss_full 0 750 421.192261 420.841370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [25:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 760 426.882812 428.746399\n",
      "loss_full 0 760 426.797363 428.662537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [25:42<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 770 424.626526 430.390442\n",
      "loss_full 0 770 424.547577 430.312012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [26:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 780 427.561371 416.591705\n",
      "loss_full 0 780 427.480225 416.506287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [26:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 790 424.154419 428.606842\n",
      "loss_full 0 790 424.080109 428.534271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [26:39<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_full 0 800 418.693634 417.673828\n",
      "loss_full 0 800 418.623749 417.607544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [26:46<00:00, 1606.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_model(\n",
       "  (lstm): LSTM(240, 2048, num_layers=3, batch_first=True)\n",
       "  (linear): Conv1d(2048, 240, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit -r1\n",
    "train_lstm_model(\n",
    "    lstm_model=LSTM_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=1,\n",
    "    filename='save-data/lstm-test_075-2.csv',\n",
    "    ema_weight=0.75,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r1\n",
    "train_lstm_model(\n",
    "    lstm_model=LSTM_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=1,\n",
    "    filename='save-data/lstm-test1_05.csv',\n",
    "    ema_weight=0.5,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r1\n",
    "train_lstm_model(\n",
    "    lstm_model=LSTM_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=1,\n",
    "    filename='save-data/lstm-test1_099.csv',\n",
    "    ema_weight=0.99,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_linear_model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(simple_linear_model, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=2048\n",
    "        self.num_layers=3\n",
    "        self.device=device\n",
    "\n",
    "        #simple single layer linear model\n",
    "        self.linear=nn.Linear(\n",
    "            in_features=240*19,\n",
    "            out_features=240*30\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x=self.linear(x)\n",
    "        return x\n",
    "        \n",
    "    def forward_test(self, x, num_steps=30):\n",
    "        res=[]\n",
    "        h=torch.zeros((self.num_layers, len(x), self.hidden_dim)).to(self.device)\n",
    "        c=torch.zeros((self.num_layers, len(x), self.hidden_dim)).to(self.device)\n",
    "        for step in range(num_steps):\n",
    "            x, (h,c)=self.lstm(x, (h,c))\n",
    "            x=x[:,-1:]\n",
    "            x=x.transpose(1,2)\n",
    "            x=self.linear(x)\n",
    "            x=x.transpose(1,2)\n",
    "            res.append(x)\n",
    "        res=torch.cat(res,1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(lmodel, data_loader, n_epochs, filename, ema_weight, device='cuda', verbose=False):\n",
    "    '''\n",
    "    Train LSTM model\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "        lmodel - torch nerual network linear model\n",
    "            model to train\n",
    "        data_loader - torch DataLoader class \n",
    "            training data for model\n",
    "        n_epochs - int\n",
    "            number of epochs to train\n",
    "        filename - string\n",
    "            filepath to save training data to\n",
    "        ema_weight - float\n",
    "            float between (0.0,1.0) for the exponential moving average weight\n",
    "        device - string, default 'cuda'\n",
    "            choose to run on gpu ('cuda') or cpu ('CPU')\n",
    "        verbose - boolean, default False\n",
    "            If true print training progress every 10 training iterations\n",
    "    -------\n",
    "    Returns\n",
    "    -------\n",
    "         Trained LSTM model\n",
    "    '''\n",
    "    \n",
    "    model=lmodel(device).to(device)\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    loss_ema=-1\n",
    "    loss_ema2=-1\n",
    "\n",
    "    data=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i_batch, sample_batch in enumerate(tqdm(train_loader, desc='Epoch %i/%i'%(epoch+1,n_epochs), disable=verbose)):\n",
    "            '''\n",
    "            TODO:\n",
    "            Deep learning model training routine\n",
    "            '''\n",
    "            inp, out=sample_batch\n",
    "            inp, out=inp.to(device), out.to(device)\n",
    "\n",
    "            # input: batch size x 60 x 49 x 4\n",
    "            # transpose: batch size x 49 x 240\n",
    "            mixed=torch.cat([inp, out], 2).transpose(1,2).reshape((-1,49,240))#.float()\n",
    "\n",
    "            y_pred=model(inp.reshape((len(inp),-1))).reshape((-1,60,30,4))\n",
    "\n",
    "            loss=(torch.mean((y_pred-out)**2))**0.5\n",
    "            optimizer.zero_grad() # set gradient to zero\n",
    "            loss.backward() # backwards propogation\n",
    "            optimizer.step() #forward step\n",
    "\n",
    "            if loss_ema<0:\n",
    "                loss_ema=loss\n",
    "            loss_ema=loss_ema*ema_weight+loss*(1-ema_weight)\n",
    "\n",
    "            if verbose and i_batch%10==0:\n",
    "                loss_str='loss %i %i %f %f'%(epoch,i_batch,loss_ema.item(),loss.item())\n",
    "                print(loss_str)\n",
    "                \n",
    "            data.append([epoch, i_batch, loss_ema.item(), loss.item()])\n",
    "    \n",
    "    columns=[\"epoch\",\"iteration\",\"loss_ema\",\"loss\"]\n",
    "    df=pd.DataFrame(dict(zip(columns, np.array(data).T)))\n",
    "    display(df)\n",
    "    df.to_csv(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 805/805 [04:01<00:00,  3.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>loss_ema</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>674.189087</td>\n",
       "      <td>674.189148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>667.140930</td>\n",
       "      <td>603.708069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>646.925781</td>\n",
       "      <td>464.989563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>621.590942</td>\n",
       "      <td>393.577423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>603.362366</td>\n",
       "      <td>439.305542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>53.114674</td>\n",
       "      <td>36.886452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>54.724529</td>\n",
       "      <td>69.213257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>54.805630</td>\n",
       "      <td>55.535534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>54.290657</td>\n",
       "      <td>49.655933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>0.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>56.497498</td>\n",
       "      <td>76.359070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  iteration    loss_ema        loss\n",
       "0      0.0        0.0  674.189087  674.189148\n",
       "1      0.0        1.0  667.140930  603.708069\n",
       "2      0.0        2.0  646.925781  464.989563\n",
       "3      0.0        3.0  621.590942  393.577423\n",
       "4      0.0        4.0  603.362366  439.305542\n",
       "..     ...        ...         ...         ...\n",
       "800    0.0      800.0   53.114674   36.886452\n",
       "801    0.0      801.0   54.724529   69.213257\n",
       "802    0.0      802.0   54.805630   55.535534\n",
       "803    0.0      803.0   54.290657   49.655933\n",
       "804    0.0      804.0   56.497498   76.359070\n",
       "\n",
       "[805 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "simple_linear_model(\n",
       "  (linear): Linear(in_features=4560, out_features=7200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_linear_model(\n",
    "    lmodel=simple_linear_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=1,\n",
    "    filename='save-data/simple-linear-090.csv',\n",
    "    ema_weight=0.90,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multilayer_linear_model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(multilayer_linear_model, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=8192\n",
    "        self.num_layers=3\n",
    "        self.device=device\n",
    "                \n",
    "        self.linear=nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=240*19, \n",
    "                out_features=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                in_features=self.hidden_dim,\n",
    "                out_features=240*30\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "#         self.linear=nn.Conv1d(\n",
    "#             in_channels=self.hidden_dim,\n",
    "#             out_channels=240,\n",
    "#             kernel_size=1\n",
    "#         )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x=self.linear(x)\n",
    "        return x\n",
    "        \n",
    "    def forward_test(self, x, num_steps=30):\n",
    "        res=[]\n",
    "        h=torch.zeros((self.num_layers, len(x), self.hidden_dim)).to(self.device)\n",
    "        c=torch.zeros((self.num_layers, len(x), self.hidden_dim)).to(self.device)\n",
    "        for step in range(num_steps):\n",
    "            x, (h,c)=self.lstm(x, (h,c))\n",
    "            x=x[:,-1:]\n",
    "            x=x.transpose(1,2)\n",
    "            x=self.linear(x)\n",
    "            x=x.transpose(1,2)\n",
    "            res.append(x)\n",
    "        res=torch.cat(res,1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 805/805 [04:07<00:00,  3.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>loss_ema</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.770264</td>\n",
       "      <td>599.770264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>688.255798</td>\n",
       "      <td>1484.625732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>665.488220</td>\n",
       "      <td>460.580475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>649.831238</td>\n",
       "      <td>508.918549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>638.979004</td>\n",
       "      <td>541.309204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>16.430296</td>\n",
       "      <td>14.909383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>16.421009</td>\n",
       "      <td>16.337429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>16.275198</td>\n",
       "      <td>14.962907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>17.299162</td>\n",
       "      <td>26.514839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>0.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>17.308247</td>\n",
       "      <td>17.390007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  iteration    loss_ema         loss\n",
       "0      0.0        0.0  599.770264   599.770264\n",
       "1      0.0        1.0  688.255798  1484.625732\n",
       "2      0.0        2.0  665.488220   460.580475\n",
       "3      0.0        3.0  649.831238   508.918549\n",
       "4      0.0        4.0  638.979004   541.309204\n",
       "..     ...        ...         ...          ...\n",
       "800    0.0      800.0   16.430296    14.909383\n",
       "801    0.0      801.0   16.421009    16.337429\n",
       "802    0.0      802.0   16.275198    14.962907\n",
       "803    0.0      803.0   17.299162    26.514839\n",
       "804    0.0      804.0   17.308247    17.390007\n",
       "\n",
       "[805 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "multilayer_linear_model(\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=4560, out_features=8192, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8192, out_features=7200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_linear_model(\n",
    "    lmodel=multilayer_linear_model,\n",
    "    data_loader=train_loader,\n",
    "    n_epochs=1,\n",
    "    filename='save-data/simple-linear-090.csv',\n",
    "    ema_weight=0.90,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_linear_df.to_csv(\"simple_linear.csv\")\n",
    "simple_linear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequential_linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4b75cd5f374b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultilayer_linear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-505b94553370>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mmultilayer_linear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential_linear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sequential_linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model=multilayer_linear_model(device).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_ema=-1\n",
    "loss_ema2=-1\n",
    "\n",
    "n_epochs=20\n",
    "sequential1_df=pd.DataFrame(dict(zip([\"epoch\",\"iteration\",\"loss_ema\",\"loss\"],[])))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        '''\n",
    "        TODO:\n",
    "        Deep learning model training routine\n",
    "        '''\n",
    "        inp, out=sample_batch\n",
    "        inp, out=inp.to(device), out.to(device)\n",
    "        \n",
    "        # input: batch size x 60 x 49 x 4\n",
    "        # transpose: batch size x 49 x 240\n",
    "        mixed=torch.cat([inp, out], 2).transpose(1,2).reshape((-1,49,240))#.float()\n",
    "        \n",
    "        y_pred=model(inp.reshape((len(inp),-1))).reshpape((-1,60,30,4))\n",
    "        \n",
    "        loss=(torch.mean((y_pred-out)**2))**0.5\n",
    "        optimizer.zero_grad() # set gradient to zero\n",
    "        loss.backward() # backwards propogation\n",
    "        optimizer.step() #forward step\n",
    "        \n",
    "        if loss_ema<0:\n",
    "            loss_ema=loss\n",
    "        loss_ema=loss_ema*0.99+loss*0.1\n",
    "            \n",
    "        if i_batch%10==0:\n",
    "#             print('loss_full', epoch, i_batch, loss_ema.item(), loss.item())\n",
    "            sequential1_df.append([epoch, i_batch, loss_ema.item(), loss.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential1_df.to_csv(\"sequential1.csv\")\n",
    "sequential1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "        #set labels\n",
    "        axs[i].set_ylabel(\"out\")\n",
    "        axs[i].set_xlabel(\"inp\")\n",
    "        \n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in val_loader:\n",
    "    print(\"test\")\n",
    "    print(sample)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
